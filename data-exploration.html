<!DOCTYPE HTML>
<!--
	Miniport by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Data Collection and Exploration</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Nav -->
			<nav id="nav">
				<ul class="container">
					<li><a href="index.html">Home</a></li>
					<li><a href="problem.html">Problem</a></li>
					<li><a href="data.html">Data</a></li>
					<li><a href="models.html">Models</a></li>
					<li><a href="synthesis.html">Synthesis</a></li>
					<li><a href="#team">Team</a></li>
				</ul>
			</nav>

		<!-- Data -->
		<article id="data-exploration" class="wrapper style3">
			<div class="container" style="margin-bottom: 5em;">
				<header>
					<h2>Here's our preprocessed data and its visualization.</h2>
					<p style="text-align: justify; margin-bottom: 1em; margin-top: 2em;">We have divided the data exploration stage into 4 subsections, namely Preprocessing for Clean Data, Time Series Analysis, Natural Language Processing, and Categorical Data Encoding. <b>Preprocessing for Clean Data</b> guarantees that the dataset handles clean data only. In this stage, the sheet is processed to only contain correct, complete, and unique data.</p> 
					<p style="text-align: justify;"><b>Time Series Analysis</b> is a useful approach for our first research question. This aids in analyzing what events triggered the spread of harmful tweets. For the second research question, <b>Natural Language Processing</b> is necessary in performing topic analysis and in identifying the most frequently mentioned implants. Finally, content type and thread language features are required to be processed via <b>Categorical Data Encoding</b> as preparation for answering our third research question.</p>
				</header>
			</div>

			<div class="container" style="margin-bottom: 5em;">
				<header>
					<h2 style="text-align: justify;">1 - Preprocessing for Clean Data</h2>
					<p style="text-align: justify;">In the preprocessing stage, we have performed different techniques to ensure that the project would involve only clean data. You may refer to this <a href="https://github.com/mspardinas/cs132-g28-covid-vaccine-implants/blob/main/misc/Data-Exploration-Encoding.ipynb">Preprocessing and Data Encoding document</a> to see how we handled the data.</p>
				</header>

				<div class="container">
					<h3 style="text-align: left;">Handling Missing Values</h3>
					<p style="text-align: justify;">Initially, the dataset had 35 features which included columns with missing values and dirty values. Upon checking for missing values, the features with missing values are Account Bio, Location, Screenshot, etc. All these features are dropped along with the some features deemed unnecessary for the project. The <b>15 retained features</b> with no missing values are <span style="background-color: #FFFF00">['ID', 'Timestamp', 'Tweet URL', 'Group', 'Keywords', 'Account handle', 'Account name', 'Account bio', 'Account type', 'Tweet', 'Tweet Translated', 'Tweet Type', 'Date posted', 'Content type', 'Reasoning', 'Thread/Tweet Language']</span>.</p>

					<h3 style="text-align: left;">Handling Outliers</h3>
					<div class="row">
						<div class="col-8 col-12-medium col-12-small" style="padding-bottom:0;">
							<img src="images/raw-CSV-scraped-tweets.png" alt="Sample raw CSV file of Scraped Tweets" style=" width: 100%; object-fit:contain; "/>
							<p style="font-size: 0.8em; margin-bottom:0; line-height:130%;" >Figure 1: Screenshot of a generated CSV file during Tweet Scraping</p>
						</div>
						<div class="col-4 col-12-medium col-12-small">
							<p style="text-align: justify; ">The screenshot of a raw CSV file of scraped tweets is shown in Figure 1. In particular, the scraping tool generated this file on 28th March 2023 using keywords "bakuna" and "laman". These <b>scraped tweets</b>, however, has gathered multiple outliers that is not suitable for the topic. Hence, the team <b>manually removed</b> the outliers so that the dataset would only involve relevant and fact-checkable tweets. There are other checks and criteria that the collectors observed when handling outliers. The general discussion of scraping and filtering of tweets are explored thoroughly in the <a href="data-collection.html">Data Collection</a> section of this portfolio.</p>
						</div>
					</div>
					

					<h3 style="text-align: left;">Ensuring Formatting Consistency</h3>
					<p style="text-align: justify;">In the document, consistency in formatting of date features and categorical features were observed. For the <span style="background-color: #FFFF00">Timestamp</span> and the <span style="background-color: #FFFF00">Date posted</span> features, we ensured that the data type is datetime. By default, the <b>format of datetime</b> in Pandas is YYYY-MM-DD HH:MM:SS. The team also observed consistency in labels of categorical features. For <span style="background-color: #FFFF00">Account type</span>, we ensured that the values can only be <b>Anonymous</b>, <b>Identified</b>, or <b>Media</b> and are case sensitive. For <span style="background-color: #FFFF00">Content type</span>, values should be <b>Emotional</b>, <b>Rational</b>, or <b>Transactional</b> and are case sensitive. For <span style="background-color: #FFFF00">Language</span>, values are guaranteed to be <b>Filipino</b>, or <b>Foreign</b> and are case sensitive</p>

					<h3 style="text-align: left;">Translating Tweets - Standardization</h3>
					<div class="row">
						<div class="col-6 col-12-medium col-12-small">
							<p style="text-align: justify;">The screenshot of the first eight Tweets and their Translations is shown in Figure 2. For translating tweets, the team used <b>Google translator</b> to obtain raw English translation of all Filipino tweets. Then, we manually checked all results and adjusted some translations for better accuracy. For Foreign tweets, the contents in the <span style="background-color: #FFFF00">Tweet</span> column were copied into the <span style="background-color: #FFFF00">Tweet translation</span> column since all Foreign tweets gathered are already in English. Translating tweets are considered <b>standardization</b> since internal consistency in terms language are insured. This process is needed for the <b>Natural Language Processing</b> section. The team also performed other normalization and standardization techniques in the Time Series Analysis section.</p>
						</div>
						<div class="col-6 col-12-medium col-12-small" style="padding-top:0;">
							<img src="images/tweets-translated.png" alt="First 8 Tweets and their Translation" style=" width: 95%; object-fit:contain; "/>
							<p style="font-size: 0.8em; line-height:130%;">Figure 2: First 8 Tweets and their Translations in the Dataset</p>
						</div>
					</div>
				</div>
			</div>

			<div class="container" style="margin-bottom: 5em;">
				<header>
					<h2 style="text-align: justify;">2 - Time Series Analysis</h2>
					<p style="text-align: justify;">For the time series analysis, we first performed feature generation to create the necessary features to represent our data. Then, the methods peformed on the time series data are binning and interpolation. This <a href="https://github.com/mspardinas/cs132-g28-covid-vaccine-implants/blob/main/misc/Data-Exploration-TimeSeries.ipynb">Time Series Analysis document</a> contains the preprocessing procedures and visualizations for our time series data.</p>
				</header>

				<div class="container">
					<h3 style="text-align: left;">Feature Generation</h3>
					<p style="text-align: justify;">The team intends to observe <b>what timeframes</b> have high frequencies of posted tweets. This will help determine what events triggered the spread of tweets containing misinfo/disinfo. To fulfill this, we created new a feature named <span style="background-color: #FFFF00">Count</span> as part of time series data. Count is the number of tweets posted in a certain time or time range. From <b>Count</b> and <b>Language</b> features, we generated two more features: <span style="background-color: #FFFF00">Filipino_Count</span> and <span style="background-color: #FFFF00">Foreign_Count</span>. Filipino_Count is the number of Filipino tweets posted given a certain time or time range. Foreign_Count is the number of Foreign tweets posted given a certain time or time range.</p>

					<h3 style="text-align: left;">Binning</h3>
					<div class="row">
						<div class="col-6 col-12-medium col-12-small" style="padding-bottom:0;">
							<img src="images/binning.png" alt="Semimonthly Binning of Time Series Data" style=" width: 100%; object-fit:contain; "/>
							<p style="font-size: 0.8em; margin-bottom:0; line-height:130%;" >Figure 3: Semimonthly Binning of Time Series Data</p>
						</div>
						<div class="col-6 col-12-medium col-12-small">
							<p style="text-align: justify; ">To organize our time series data, the group performed data binning on the newly generated features. The binning technique employed is via <b>grouping</b>. The features are grouped as sum of <span style="background-color: #FFFF00">Count</span>, <span style="background-color: #FFFF00">Filipino_Count</span>, or <span style="background-color: #FFFF00">Foreign_Count</span> corresponding to its columns in a semimonthly manner as shown in Figure 3. For further details about the binned data, it has 71 rows which implies having <b>71 semimonthly timeranges</b> obtained from 15 January 2021 to 31 December 2023.</p>
						</div>
					</div>

					<h3 style="text-align: left;">Interpolation</h3>
					<div class="row">
						<div class="col-6 col-12-medium col-12-small" style="padding-bottom:0;">
							<img src="images/interpolation.png" alt="Interpolation of the Time Series Data" style=" width: 100%; object-fit:contain; "/>
							<p style="font-size: 0.8em; line-height:130%;">Figure 4: Interpolation of the Time Series Data (Hourly)</p>
						</div>
						<div class="col-6 col-12-medium col-12-small">
							<p style="text-align: justify;">Since our time-series data has in semimonthly binning, resampling the data by decreasing the period length would result to missing values. The team resampled the data by adjusting the period length from semimonthly <b></b>to hourly</b>. We also have increased the rows from 71 <b>to 25561</b>. To fill in the missing values on the newly resampled table, we performed <b>cubic spline interpolation with K=3</b>. Shown in Figure 4 is a table of the interpolated time series data of of <span style="background-color: #FFFF00">Count</span>, <span style="background-color: #FFFF00">Filipino_Count</span>, and <span style="background-color: #FFFF00">Foreign_Count</span>. This interpolation is an approximate of the frequencies of misinfo/disinfo Tweets being posted every hour from 15 January 2021 to 31 December 2023.</p>
						</div>
					</div>
					

					<h3 style="text-align: left;">Line Graph - Time Series</h3>
					<p style="text-align: justify; margin-bottom: 1em;">To visualize our binned data and interpolated data, <b>line graphs</b> were generated to display the differences among <span style="background-color: #FFFF00">Count</span>, <span style="background-color: #FFFF00">Filipino_Count</span>, and <span style="background-color: #FFFF00">Foreign_Count</span> features accross time. The first line graph displays the original time series data which records the tweet frequency in a <b>semimonthly</b> interval. The second line graph displays the interpolated data that records tweet frequency in an <b>hourly</b> manner.</p>
					<img src="images/line-graphs.png" alt="Line Graphs" style=" width: 90%; object-fit:contain;"/>
					<p style="font-size: 0.8em; margin-bottom: 1em; line-height:130%;">Figure 5: (A) Line Graph of Time Series Data with Semimonthly Binning, and (B) Line Graph of Interpolated Time Series Data in Hours </p>

					<p style="text-align: justify; margin-bottom: 0.5em;">Notice that the interpolated graph has smoother plot since we have provided estimated values that increased the number of data points. We can also observe the following trends for <span style="background-color: #FFFF00">Count</span>, <span style="background-color: #FFFF00">Filipino_Count</span>, and <span style="background-color: #FFFF00">Foreign_Count</span> features:</p>
					<ul class="container" style="font-size: 0.90em;">
						<li><p style="text-align: left; margin-bottom: 0;">All tweets considered, many tweets were posted on the <b>second half of May 2021</b>.</p></li>
						<li><p style="text-align: left; margin-bottom: 0;">For Filipino Tweets, many tweets were posted on the <b>first half of August 2021</b>.</p></li>
						<li><p style="text-align: left;">For Foreign Tweets, many tweets were posted on the <b>second half of December 2022</b>.</p></li>
					</ul>


					<h3 style="text-align: left;">Normalization and Standardization</h3>
					<p style="text-align: justify; margin-bottom: 0.5em;">First, we looked into the mean and standard deviation of <span style="background-color: #FFFF00">Count</span>, <span style="background-color: #FFFF00">Filipino_Count</span>, and <span style="background-color: #FFFF00">Foreign_Count</span> features. When all samples are considered in our dataset, approximately <b>two tweets</b> relevant to our topic are being posted semimonthly on average. Filipino_Count has <b>narrower spread</b> than Foreign_Count. When combined, we obtained a <b>wider spread</b>.</p>

					<p style="text-align: justify; margin-bottom: 1em;">Then, we <b>standardized</b> our time series data by obtaining the <b>Z-scores</b> of all data points. Upon standardizing the data, we could observe the following: (1) there are <b>two outliers</b> in <span style="background-color: #FFFF00">Count</span>; (2) there are <b>two outliers</b> in <span style="background-color: #FFFF00">Filipino_Count</span>; and (3) there are <b>three outliers</b> in <span style="background-color: #FFFF00">Foreign_Count</span>. Shown below in Figure 6 are the visualizations of our standardized data to easily identify the outliers per feature.</p>

					<img src="images/standardized.png" alt="Standardized Time Series Data" style=" width: 90%; object-fit:contain;"/>
					<p style="font-size: 0.8em; margin-bottom: 1em; width: 63%; margin-left:auto; margin-right:auto; line-height:130%; min-width:300px;">Figure 6: (A) Distribution for Standardized Count Feature, (B) Distribution for Standardized Filpino_Count Feature, and (C) Distribution for Standardized Foreign_Count Feature</p>
				</div>
			</div>

			<div class="container" style="margin-bottom: 5em;">
				<header>
					<h2 style="text-align: justify;">3 - Natural Language Processing</h2>
					<p style="text-align: justify;">For Natural Language Processing, we based it off from the preprocessing guide provided in this <a href ="https://colab.research.google.com/drive/1-h9ucS3Ly7Kz1rypksUISBC8i8dski5m?usp=sharing">Python Notebook</a> by Sir Regonia. which uses <b>Natural Language Toolkit</b>. Since our data is in text form, we started with data <span style="background-color: #FFFF00">cleaning</span> by removing emoticons/emojis and converting all characters to lower case. Then, <span style="background-color: #FFFF00">tokenization</span> is done to break complex tweets into more manageable/explorable data. Stop words are also removed to eliminate commonly occurrings English words. Lastly, <span style="background-color: #FFFF00">stemming</span> and <span style="background-color: #FFFF00">lemmatization</span> is done to reduce each word to their base form and ensure it is a valid word. To represent our analysis, we used a bar graph to represent the frequency of certain types of implants over our whole dataset.</p>
				</header>

				<div class="container">
					<h3 style="text-align: left;">Cleaning</h3>
					<p style="text-align: justify; margin-bottom: 1em;">First, each user's tweets is cleaned by <b>removing emojis/emoticons</b>, and handling certain special text faces. This is done by replacing every emoji and special text face in our dataset into a text or keyword representing it, such as transforming ðŸ¥´ into "woozy_face".</p>
					
					<img src="images/nlp-01-emoticons.png" alt="NLP Cleaning - Handling of Emoticons" style=" width: 90%; object-fit:contain;"/>
					<p style="font-size: 0.8em; margin-bottom: 3em; width: 63%; margin-left:auto; margin-right:auto; line-height:130%; min-width:300px;">Figure 7: Handling emojis/emoticons and special text</p>
					
					<h3 style="text-align: left;">Lower Casing</h3>
					<p style="text-align: justify; margin-bottom: 1em;">Next, each character in every word in every tweet is lowercased. This is to ensure <b>case-insensitive matching</b> later on once we tally the frequency of each kind of implant or foreign substance a user mentions the COVID-19 vaccine has. Moreoever, punctuations are also removed.</p>
					
					<img src="images/nlp-02-lowercasing.png" alt="NLP Cleaning - Lowercasing and removing punctuations" style=" width: 90%; object-fit:contain;"/>
					<p style="font-size: 0.8em; width: 63%; margin-bottom: 3em; margin-left:auto; margin-right:auto; line-height:130%; min-width:300px;">Figure 8: Lowercasing and punctuation removal</p>

					<h3 style="text-align: left;">Tokenization and Stop Words Removal</h3>
					<p style="text-align: justify; margin-bottom: 1em;">Each tweet is then tokenized, and English stop words are removed. This is to remove commonly occurring words in a tweet, which further cleans our dataset by ensuring that only words which have weight or impact during analysis are kept. Through this procedure, our analysis is restricted only to <b>meaningful</b> and <b>informative words</b> that contribute to the overall context and understanding of our project.</p>
					
					<img src="images/nlp-03-token.png" alt="NLP Cleaning - Tokenization and stop words removal" style=" width: 90%; object-fit:contain;"/>
					<p style="font-size: 0.8em; width: 63%; margin-bottom: 3em; margin-left:auto; margin-right:auto; line-height:130%; min-width:300px;">Figure 9: Tokenization and Stop Words removal</p>

					<h3 style="text-align: left;">Stemming and Lemmatization</h3>
					<p style="text-align: justify; margin-bottom: 1em;">Stemming and lemmatization are also applied to improve <b>keyword frequency analysis</b> which will be used later on once we generate our bar graph for feature comparison. Stemming helps by normalizing words, and lemmatization helps in producing meaningful base forms of each word. This also helps in reducing word or frequency noise by consolidating similar word variations into a single base form.</p>
					
					<img src="images/nlp-04-stemlemma.png" alt="Stemming and Lemmatization" style=" width: 90%; object-fit:contain;"/>
					<p style="font-size: 0.8em; margin-bottom: 3em; width: 63%; margin-left:auto; margin-right:auto; line-height:130%; min-width:300px;">Figure 10: Stemming and Lemmatization</p>

					<h3 style="text-align: left;">Bar Graph - Feature Comparison</h3>
					<div class="row">
						
						<div class="col-6 col-12-medium col-12-small">
							<p style="text-align: justify; margin-bottom: 0.5em;">Lastly, to gain some insight on our dataset, we opted to count the <b>frequency</b> of different kinds of implants or foreign substances users tweet the COVID-19 might have in their tweet. Also note that we opted to explore in analyzing our lemmatized dataset. We separated kinds of implants and foreign substances into <span style="background-color: #FFFF00">five (5) kinds</span>: Magnet, Microchip, Water, Toxin, and Others. Each category and their associated keywords are detailed below:</p>
							<ul class="container"  style="font-size: 0.90em; line-height: 1.8em; margin-bottom: 1em;">
								<li><p style="text-align: left; margin-bottom: 0;"><b>Magnet</b>: "magnet", "magnetized", "magnetic", "magnetizes", "spoon", "coin", "fridge", "refrigerator", "shock", "electric", "electrical", "metal"</p></li>
								<li><p style="text-align: left; margin-bottom: 0;"><b>Microchip</b>: "microchip", "micro", "chip", "simcard", "sim", "card", "5g", "track", "tracking", "bluetooth"</p></li>
								<li><p style="text-align: left; margin-bottom: 0;"><b>Water</b>: "water", "canal", "aquafina", "aqua", "tap", "flood"</p></li>
								<li><p style="text-align: left; margin-bottom: 0;"><b>Toxin</b>: "poison", "ccpvirus", "toxin"</p></li>
								<li><p style="text-align: left; margin-bottom: 0;"><b>Others</b>: "salt", "saline", "monosodium", "nanoparticles", "sugar"</p></li>
							</ul>
						</div>
						<div class="col-6 col-12-medium col-12-small" style="padding-top: 0em; align-items: center; display: flex; justify-content: center;">
							<div>
								<img src="images/nlp-05-nlpbargraph.png" alt="Bar Graph for Feature Comparison" style=" width: 90%; object-fit:contain; "/>
								<p style="font-size: 0.8em; margin-bottom: 1em; width: 63%; margin-left:auto; margin-right:auto; line-height:130%; min-width:300px;">Figure 11: Bar Graph for Feature Comparison</p>
							</div>
							
						</div>
					</div>
					
					<p style="text-align: justify;">Figure 11 displays the frequency each category has over our whole dataset. From this, we can gather that most users tweet that the COVID-19 vaccine has a <span style="background-color: #FFFF00">Microchip implant</span>. Second, users tweet that the COVID-19 vaccine makes them <span style="background-color: #FFFF00">magnetic</span>. And third, tweets claims that the COVID-19 vaccine is fake and it only contains <span style="background-color: #FFFF00">water</span>. You may view our NLP preprocessing and data exploration more in our <a href="https://github.com/mspardinas/cs132-g28-covid-vaccine-implants/blob/main/misc/Data-Exploration-NLP.ipynb">NLP Python Notebook</a>.</p>
										
				</div>
			</div>

			<div class="container" style="margin-bottom: 5em;">
				<header>
					<h2 style="text-align: justify;">4 - Categorical Data Encoding</h2>
					<p style="text-align: justify;">For categorical data encoding, we used one hot encoding technique to convert categorical data into <b>numerical values</b>. The team needed to transform these features to easily observe whether there is a difference between the content type of Philippine-based and Foreign-based tweets. <b>One Hot Encoding</b> is the chosen method since these features are nominal which lack inherent order. You may refer to the <a href="https://github.com/mspardinas/cs132-g28-covid-vaccine-implants/blob/main/misc/Data-Exploration-Encoding.ipynb">Preprocessing and Data Encoding document</a> for this section.</p>
				</header>

				<div class="container">
					<h3 style="text-align: left;">One Hot Encoding</h3>
					<img src="images/one-hot-encoded.png" alt="One Hot Encoded Categorical Features" style=" width: 100%; object-fit:contain;"/>
					<p style="font-size: 0.8em; margin-bottom: 1em; line-height:130%;">Figure 12: (A) One Hot Encoded Account type, (B) One Hot Encoded Content type, and (C) One Hot Encoded Language feature </p>
					<p style="text-align: justify; ">Shown in Figure 12 are the one hot encoded features. For each category of a feature, a new <b>binary feature</b> is created. The first feature we have implemented one hot encoding is for the <span style="background-color: #FFFF00">Account type</span>. Figure 12-A shows the encoded table for these labels. Another feature that needs data encoding is <span style="background-color: #FFFF00">Content type</span>. Figure 12-B shows the encoded table for these categories. Lastly, we also employed encoding on <span style="background-color: #FFFF00">Thread/Tweet Language</span>. Figure 12-C shows the encoded table for this feature. Note that <b>0</b> represents the <b>absence</b> and <b>1</b> represents the <b>presence</b> of that categorical value.</p>
					

					<h3 style="text-align: left;">Heat Map - Feature Correlation</h3>
					<div class="row" style="flex-direction: row-reverse;">
						<div class="col-8 col-12-medium col-12-small">
							<img src="images/heat-map.png" alt="Content type and Language feature Correlation" style=" width: 90%; object-fit:contain; "/>
							<p style="font-size: 0.8em; margin-bottom: -1em; line-height:130%;">Figure 13: Content type and Language feature Correlation</p>
						</div>
						<div class="col-4 col-12-medium col-12-small">
							<p style="text-align: justify; margin-bottom: 1em;">In the third research question of the project, we are looking for the <b>difference</b> in terms of content type between Filipino and Foreign misinformed tweets about COVID-19 vaccine implants. To explore this matter, the team visualized the correlation of the content type categories and the language feature categories using the <b>Heat Map - Feature Correlation</b> as shown in Figure 13. First, the visualization is achieved by merging the encoded tables of the <span style="background-color: #FFFF00">Content type</span> and the <span style="background-color: #FFFF00">Thread/Tweet Language</span> features. Then, we let Pandas tool process the merged table and create the plot.</p>
							<p style="text-align: justify; margin-bottom: 0.5em;">From the Heat Map - Feature Correlation, the team arrived with the following <b>observations</b> to help understand our dataset:</p>
						</div>
					</div>
					<ul class="container"  style="font-size: 0.90em;">
						<li><p style="text-align: left; margin-bottom: 0;">there is a <b>moderate positive</b> correlation between <span style="background-color: #FFFF00">Emotional</span> tweets and <span style="background-color: #FFFF00">Filipino</span> tweets, with a value of 0.34</p></li>
						<li><p style="text-align: left; margin-bottom: 0;">there is a <b>moderate positive</b> correlation between <span style="background-color: #FFFF00">Rational</span> tweets and <span style="background-color: #FFFF00">Foreign</span> tweets, with a value of 0.33</p></li>
						<li><p style="text-align: left; margin-bottom: 0;">there is a <b>moderate negative</b> correlation between <span style="background-color: #FFFF00">Emotional</span> tweets and <span style="background-color: #FFFF00">Foreign</span> tweets, with a value of -0.34</p></li>
						<li><p style="text-align: left; margin-bottom: 0;">there is a <b>moderate negative</b> correlation between <span style="background-color: #FFFF00">Rational</span> tweets and <span style="background-color: #FFFF00">Filipino</span> tweets, with a value of -0.33</p></li>
						<li><p style="text-align: left;">the <span style="background-color: #FFFF00">Transactional</span> tweets have <b>weak linear relationships</b> among all other categories</p></li>
					</ul>
				</div>
			</div>

		</article>

		<!-- Team -->
			<script src="escapedTeam.js"></script>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
